---
layout:     post
title:      CS229-学习理论
subtitle:   机器学习
date:       2019-12-15
author:     Pkun
header-img: img/stfml.jpg
catalog: true
tags:
    - 机器学习
---

# CS229 课程讲义中文翻译

大部分内容来自CS229吴恩达老师的课程讲义，感谢翻译

| 原作者 | 翻译 | 校对 |
| --- | --- | --- |
| [Andrew Ng  吴恩达](http://www.andrewng.org/) | [CycleUser](https://www.zhihu.com/people/cycleuser/columns) | [XiaoDong_Wang](https://github.com/Dongzhixiao) |


|相关链接|
|---|
|[Github 地址](https://github.com/Kivy-CN/Stanford-CS-229-CN)|
|[知乎专栏](https://zhuanlan.zhihu.com/MachineLearn)|
|[斯坦福大学 CS229 课程网站](http://cs229.stanford.edu/)|
|[网易公开课中文字幕视频](http://open.163.com/movie/2008/1/M/C/M6SGF6VB4_M6SGHFBMC.html)|


## 学习理论

### 预先准备

#### 泛化误差

一个推测模型（hypothesis）的**泛化误差（generalization error）**（稍后再给出正式定义），正是那些不属于训练集的样本潜在的预期偏差（expected error on examples not necessarily in the training set）。

#### 偏差（欠拟合）

**偏差（bias）** 定义为预期的泛化误差（expected generalization error），即便我们要去拟合的对象是一个非常大的甚至是无限的训练数据集。

#### 方差（过拟合）

很可能我们基于数据拟合出来的模型可能碰巧只适合于眼下这个小规模的有限的训练集，而并不能反映 $x$ 和 $y$ 之间更广泛的关系。通过对训练集拟合得到的这个“不太靠谱的（spurious）”的模式，我们得到的可能也就是一个有很大泛化误差（large generalization error）的模型。这样的话，我们就说这个模型的**方差**很大（large variance）$^1$。



通常情况下，咱们需要在偏差（bias）和方差（variance）之间进行权衡妥协。如果我们的模型过于“简单（simple）”，而且参数非常少，那这样就可能会有很大的偏差（bias），而方差（variance）可能就很小；如果我们的模型过于“复杂（complex）”，有非常多的参数，那就可能反过来又特别大的方差（variance），而偏差（bias）就会小一些。在上面三种不同拟合的样例中，用二次函数来进行拟合得到的效果，明显是胜过一次线性拟合，也强于五次多项式拟合。


### 引理

引理1 (联合约束，The union bound)。设 $A_1, A_2, ..., A_k$ 是 $k$个不同事件（但不一定互相独立），则有：

$$
P(A_1\cup...\cup A_k)\leq P(A_1)+...+P(A_k)
$$

引理2 (Hoeffding 不等式) 。设 $Z_1,...,Z_m$ 是 $m$ 个独立的并且共同遵循伯努利分布（Bernoulli($\phi$) distribution）的随机变量（independent and identically distributed (iid) random variables）。例如：$P(Z_i =1)=\phi$ 而 $P(Z_i =0)= 1 - \phi$. 设 $\hat\phi=(\frac1m)\sum^m_{i=1}Z_i$ 是这些随机变量的平均值，然后设任意的 $\gamma \geq 0$ 为某一固定值（fixed），则有：

$$
P(|\phi-\hat\phi|>\gamma)\leq 2\exp (-2\gamma^2m)
$$

上面这个引理（在机器学习理论里面也称为 **切尔诺夫约束，Chernoff bound** ）表明，如果我们我们从一个伯努利分布的随机变量中选取平均值 $\hat\phi$ 来作为对 $\phi$ 的估计值，那么只要 $m$ 足够大，我们偏移真实值很远的概率就比较小。另外一种表述方式是：如果你有一个有偏差的硬币（biased coin），抛起来落下人头朝上的概率是 $\phi$，如果你抛了 $m$ 次，然后计算人头朝上的比例，若 $m$ 非常大，那么这个比例的值，就是一个对 $\phi$ 的一个概率很高的很好的估计。


### 经验误差（empirical error）

假设我们有一个给定的训练集 $S = \{(x^{(i)},y^{(i)});i = 1,...,m\}$，其样本规模为 $m$，集合中的训练样本 $(x^{(i)},y^{(i)})$ 是服从某概率分布 $D$ 的独立且同分布的随机变量。设一个假设（hypothesis）为$h$，我们则用如下的方法定义训练误差（也称为学习理论中的**经验风险 empirical risk** 或者**经验误差 empirical error）**：

$$
\hat\epsilon(h) =\frac1m\sum^m_{i=1}1\{h(x^{(i)})\neq y^{(i)}\}
$$

这个值只是假设模型 $h$ 分类错误样本占据训练样本总数的分数。

### 泛化误差（generalization error）

可以定义泛化误差（generalization error）为：

$$
\epsilon(h) =P_{(x,y)\sim D}(h(x)\neq y)
$$

$\epsilon(h)$ 的这个定义实际上也就相当于，基于分布 $D$ 给出的一个新的样本 $(x, y)$ ，假设模型 $h$ 对该样本分类错误的概率。


要注意，这里我们有一个预先假设，也就是训练集的数据与要用来检验假设用的数据都服从同一个分布 $D$（这一假设存在于对泛化误差的定义中）。这个假设通常也被认为是 PAC 假设之一。

> PAC 是一个缩写，原型为“probably approximately correct”，这是一个框架和一系列假设的集合，在机器学习理论中的很多结构都是基于这些假设而证明得到的。这个系列假设中**最重要的两个，就是训练集与测试集服从同一分布，以及训练样本的独立性。**


### 经验风险最小化（ERM）

假设 $h_\theta (x) = 1\{\theta^T x \geq 0\}$。拟合参数 $\theta$ 的一个思路就是可以使训练误差（training error）最小化，然后选择取最小值的时候的 $\theta$ ：

$$
\hat\theta=arg\min_\theta\hat\epsilon(h_\theta)
$$

我们把上面这个过程称之为**经验风险最小化**（empirical risk minimization，缩写为 ERM），而这种情况下通过学习算法得到的假设结果就是 $\hat h = h_{\hat\theta}$ 。


我们把通过学习算法所使用的**假设类（hypothesis class）$H$** 定义为所有分类器的集合（set of all classifiers）。对于线性分类问题来说，$H = \{h_\theta : h_\theta(x) = 1\{\theta^T x \geq 0\}, \theta \in R^{n+1}\}$，是一个对 $X$（输入特征） 进行分类的所有分类器的集合，其中所有分类边界为线性。更广泛来说，假设我们研究神经网络（neural networks），那么可以设 $H$ 为能表示某些神经网络结构的所有分类器的集合。

现在就可以把 经验风险最小化（ERM）看作是对函数类 $H$ 的最小化，其中由学习算法来选择假设（hypothesis）：

$$
\hat h=arg\min_{h\in H}\hat\epsilon(h)
$$

