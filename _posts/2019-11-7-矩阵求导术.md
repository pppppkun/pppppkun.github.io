---
layout:     post
title:      矩阵求导术·上
subtitle:   数学
date:       2019-11-7
author:     Pkun
header-img: img/matrix-head.jpg
catalog: true
tags:
    - 线性代数
    - 机器学习
---

# 前言

矩阵求导的技术，在统计学、控制论、机器学习等领域有广泛的应用。在本人阅读西瓜书的过程中发现这项技术非常的重要。在学习了一段时间后，准备写一篇博客来总结一下。分作两篇，上篇讲标量对矩阵的求导术，下篇讲矩阵对矩阵的求导术。本文使用小写字母$x$表示标量，粗体小写字母 $\pmb x$ 表示（列）向量，大写字母$X$表示矩阵。

## 定义

对于标量$f$对矩阵$X$的导数，我们定义其为 $\frac{\partial f}{\partial X} = [\frac{\partial f}{\partial X_{ij}}]$

即$f$对$X$逐个元素求导并排成和$X$一样尺寸的矩阵，然而这个定义在计算中并不好用，原因是因为对函数比较复杂时，对逐个元素求导会很麻烦（可以想象对一堆元素求偏微分）


为什么这么麻烦呢？很容易想到矩阵是一个整体，我们对逐个元素求导显然破坏了它的整体性，那如果我们从整体出发呢？

### 修改

在一元微积分中我们有导数与微分的关系 $d f =f'(x)dx$，在多元微积分中，我们有也有导数和微分的关系 $df = \sum_{i=1}^n \frac{\partial f}{\partial x_i} dx_i$，即全微分

进一步的，我们还有 $ \sum_{i=1}^n \frac{\partial f}{\partial x_i} dx_i = (\frac{\partial f}{\partial \pmb{x}})^T d\pmb{x}$

在这里我们将$df$看成一个n*1的向量，因此，全微分可以看成$ \frac{\partial f}{\partial \pmb{x}}$ 和 $d \pmb{x}$做内积。

根据以上的结论，我们将矩阵导数和微分建立联系，有 $df = \sum _{i=1}^m \sum_{j=1}^n \frac{\partial f}{\partial X_{ij}} d{X_{ij}}$

进一步的，我们可以推导出上式即为$tr((\frac{\partial f}{\partial X})^T dX)$（相同尺寸的矩阵的内积为某一矩阵转置与另一矩阵的积的迹)


现在我们来建立运算法则

## 运算法则

- $d(X +Y) = dX + dY$ $d(X-Y)=dX-dY$
- $d(XY) = dXY + XdY$
- $d(X^T) = (dX)^T$
- $dX^{-1} = (dX)^{-1}$
- $d|X| = tr(X^*dX)$ 这个可以用Laplace展开证明
    > 张贤达.《矩阵分析与应用》.p279
- $d(X\odot Y) = dX \odot Y + X \odot dY$ 符号$\odot$表示逐元素相乘

- $d \sigma (X) = \sigma'(X) \odot dX, \sigma(X) = [\sigma(X_{ij})]$是逐元素标量函数运算


$$ X =
 \left[
 \begin{matrix}
   X_{11} & X_{12}\\
   X_{21} & X_{22}\\
  \end{matrix}
  \right]
$$ 
$$
 dsin(X) = 
 \left[
    \begin{matrix}
    cosX_{11}dX_{11} & cosX_{12}dX_{12} \\
    cosX_{21}dX_{21} & cosX_{22}dX_{22} \\
    \end{matrix}
    \right]
= cos(X) \odot dX
$$

我们试图利用矩阵导数与微分的联系$df = tr(\frac{\partial f}{\partial X}^T dX)$，在求出左侧的微分$df$后，该如何写成右侧的形式并得到导数呢？这需要一些迹技巧(trace trick)

### trace trick

- 标量的迹 $a = tr(a)$
- 转置 $tr(A^T) = tr(A)$
- 线性 $tr(A+B) = tr(A) + tr(B)$
- 乘法交换 $tr(AB) = tr(BA)$ 其中$A,B^T$尺寸相同，两侧都等于$\sum_{i,j}A_{ij}B_{ji}$
- 逐元素 $tr(A^T(B \odot C)) = tr((A \odot B)^T C)$ 具体的值同上分析即可

观察一下可以**断言**，若标量函数$f$是矩阵$X$经**加减乘法、逆、行列式、逐元素函数**等运算构成，则使用相应的运算法则对$f$**求微分**，再使用迹技巧给$df$**套上迹**并将其它项交换至$dX$左侧，对照导数与微分的联系$df = tr(\frac{\partial f}{\partial X}^T dX)$，即能得到导数。


特别地，若矩阵退化为向量，对照导数与微分的联系$df = \frac{\partial f}{\partial \pmb x}^T d \pmb x$，即能得到导数。

### 复合

我们不能随意沿用标量的链式法则，因为矩阵对矩阵的导数$\frac{\partial Y}{\partial X}$还没有定义。链式法则是从何而来的呢？源头依然是微分。（微分真的很好用）
我们依然从微分开始建立复合求导

$df = tr(\frac{\partial f}{\partial Y}^T dY)$，然后再将$dY$用$dX$表示出来，然后再带入，并使用迹技巧将其他项交换到$dX$的左侧，就可以得到$\frac{\partial f}{\partial X}$

## 栗子

线性回归：$ \pmb l = \vert\vert X \pmb w- \pmb y\vert\vert ^ 2$，求$\pmb w$的最小二乘估计

解： 即计算 $\frac{\partial \pmb l}{\partial \pmb w}$的零点。同时这是标量对向量的导数，我们将向量看成是退化的矩阵

$$
\pmb l = (X \pmb w - \pmb y)^T (X \pmb w - \pmb y)
$$

$$
d \pmb l = (Xd \pmb w )^T(X \pmb w - \pmb y) + (X \pmb w - y)^T(X d\pmb w) = 2(X \pmb w - \pmb y)^T X d \pmb w
$$

对照导数与微分的联系$d \pmb l = \frac{\partial \pmb l}{\partial \pmb w}^T d \pmb w$有

$$
\frac{\partial \pmb l}{\partial \pmb w}^T d \pmb w = 2(X \pmb w - \pmb y)^T X d \pmb w
$$

所以

$$
\frac{\partial \pmb l}{\partial \pmb w} = 2X^T(X \pmb w - \pmb y) = 0
$$

即

$$
X^TX \pmb w = X^T \pmb y
$$

所以

$$
\pmb w = (X^TX)^{-1}X^T \pmb y
$$




